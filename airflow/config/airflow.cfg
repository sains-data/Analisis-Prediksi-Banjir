[core]
dags_folder = /opt/airflow/dags
hostname_callable = socket.getfqdn
default_timezone = utc
executor = CeleryExecutor
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
max_active_tasks_per_dag = 16
max_active_runs_per_dag = 16
parallelism = 32

[celery]
broker_url = redis://airflow-redis:6379/0
result_backend = db+postgresql://airflow:airflow@airflow-postgres/airflow
celery_app_name = airflow.executors.celery_executor
worker_concurrency = 16

[database]
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow

[webserver]
base_url = http://localhost:8085
web_server_port = 8080
worker_refresh_batch_size = 1
worker_refresh_interval = 6000
secret_key = temporary_key

[scheduler]
dag_dir_list_interval = 300
child_process_timeout = 60
catchup_by_default = False
max_threads = 2

[operators]
default_owner = airflow

[logging]
base_log_folder = /opt/airflow/logs
logging_level = INFO

[metrics]
statsd_on = False

[secrets]
backend =
backend_kwargs =
